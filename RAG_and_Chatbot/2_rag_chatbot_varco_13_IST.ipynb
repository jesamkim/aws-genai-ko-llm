{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efee779e-2f33-451c-b7cf-415f1491b1fa",
   "metadata": {},
   "source": [
    "# RAG (Retrieval Augmented Generation) and Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d0cbda-237a-4679-9b67-bbaee014164b",
   "metadata": {},
   "source": [
    "## Pre-Requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a0f813-6932-444b-9abe-7d85aca7d11b",
   "metadata": {},
   "source": [
    "### LLM model (VARCO) deploy in SageMaker\n",
    "Make sure that you have ran the Notebook 1_deploy-varco_model_13_IST.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabafe9c-ad23-4ebc-8a05-923c0168948a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c182bbee-8dfe-4321-9c2b-9e7c19007843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"VARCO_ENDPOINT\"]=endpoint_name\n",
    "print(os.environ[\"VARCO_ENDPOINT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175eb15b-baf6-468e-8612-8be8bd121e3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!apt update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9654b9fb-e9b7-4aea-a53b-2532225d037a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!apt install wkhtmltopdf -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f236cc4-5b4a-4cd1-b618-568615935ac8",
   "metadata": {},
   "source": [
    "### Install certain libraries which are needed for this run.\n",
    "These are provided in the requirements.txt or you can run these cells to fine control which libraries you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f06cfc-04a8-4c05-bb05-81afb87f0c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5489aa5-387b-411d-bf91-46e8c40f200e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain==0.0.161 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b7502e-5d8b-491e-aa74-4190cfaafa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install chromadb==0.3.21 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd86a6d-861c-47ac-994c-c6f76139e56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain==0.0.161 boto3 html2text jinja2 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a663021e-ed72-438c-ad41-e7499a79dd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faiss-cpu==1.7.4 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cc98a3-f790-4fa8-b6e1-3a36eb91fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pypdf==3.8.1 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ff5932-0216-4b7c-93ac-cc98a8f59fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==4.24.0 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7387c952-e1a4-4146-b3f5-cd100d845bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence_transformers==2.2.2 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29080a1-2495-4dc8-80a9-3a23d4cb9805",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pdfkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4da5b3e-c561-4d5f-ae2b-8259a334c42d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sentence_transformers \n",
    "sentence_transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff62bf1a-d310-4728-9599-000119f3d259",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"all libraries installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ffaebc-fd87-4f19-815c-6a1d8a5d760a",
   "metadata": {},
   "source": [
    "### Import statements for our chain and indexers. We are not using any explicit agent here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30079014-ff7c-4369-9964-cb6952df475f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from aws_langchain.kendra_index_retriever import KendraIndexRetriever\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain import SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import ContentHandlerBase\n",
    "from langchain.prompts import PromptTemplate\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import sagemaker, boto3, json\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.model import Model\n",
    "from sagemaker import image_uris, model_uris, script_uris, hyperparameters\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.utils import name_from_base\n",
    "from typing import Any, Dict, List, Optional\n",
    "from langchain.embeddings import SagemakerEndpointEmbeddings\n",
    "from langchain.llms.sagemaker_endpoint import ContentHandlerBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88e0304-58a9-46c5-8999-e7b0411fc430",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import jinja2\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4470f341-cc81-4660-b9a6-d04896992841",
   "metadata": {},
   "source": [
    "### [Optiona] Deploy a GPT-J embeddings Model - so we can use that to generate the embeddings for the documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca003a4f-0834-4820-bd24-2dbd3b03cfd4",
   "metadata": {},
   "source": [
    "skip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7e1a51-ed48-4e4c-96b1-9469b90a97af",
   "metadata": {},
   "source": [
    "### Use HuggingFaceEmbeddings in the workshop setting. \n",
    "If you are in a workshop, please use the below code. If you are using GPTJ model for generating the embeddings, please comment the below cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d534face-5d83-4043-ae73-0677134aede2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from typing import Any, Dict, List, Optional\n",
    "from pydantic import BaseModel, Extra, Field\n",
    "from langchain.embeddings.base import Embeddings\n",
    "import numpy as np\n",
    "\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "\n",
    "\n",
    "class CustomHFEmbeddings(HuggingFaceEmbeddings):\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Compute doc embeddings using a HuggingFace transformer model.\n",
    "\n",
    "        Args:\n",
    "            texts: The list of texts to embed.\n",
    "\n",
    "        Returns:\n",
    "            List of embeddings, one for each text.\n",
    "        \"\"\"\n",
    "        texts = list(map(lambda x: x.replace(\"\\n\", \" \"), texts))\n",
    "        embeddings = self.client.encode(texts, **self.encode_kwargs)\n",
    "        #- (22, 1536)\n",
    "        print(f\"CustomHFEmbeddings::embed_documents::shape:returned -- > {embeddings.shape}:\")\n",
    "        \n",
    "        return embeddings.tolist()\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "            \"\"\"Compute query embeddings using a HuggingFace transformer model.\n",
    "\n",
    "            Args:\n",
    "                text: The text to embed.\n",
    "\n",
    "            Returns:\n",
    "                Embeddings for the text.\n",
    "            \"\"\"\n",
    "            text = text.replace(\"\\n\", \" \")\n",
    "            embedding = self.client.encode(text, **self.encode_kwargs)\n",
    "            print(f\"CustomHFEmbeddings::QUERY::shape:returned -- > {embedding.shape}:\")\n",
    "            return embedding.tolist()\n",
    "\n",
    "hf_embeddings = CustomHFEmbeddings(model_name=model_name, model_kwargs=model_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5a04ce-787d-4042-b789-4a8c47e54c53",
   "metadata": {},
   "source": [
    "### Test the VARCO model \n",
    "Testing VARCO 13B IST model for answering a random question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08761a46-011e-4f90-9dd5-244ac1db9368",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "runtime = boto3.client(\"runtime.sagemaker\")\n",
    "\n",
    "model_name = endpoint_name\n",
    "content_type = \"application/json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55423e0e-a96f-4dbd-8443-9fa61e968189",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = {\"text\":\"Answer this question below, How can it help me?\"}\n",
    "print(f\"Question being asked is -- > {prompt}:\")\n",
    "\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=model_name,\n",
    "    ContentType=content_type,\n",
    "    Accept=\"application/json\",\n",
    "    Body=json.dumps(prompt)\n",
    ")\n",
    "\n",
    "json.load(response[\"Body\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268aa75f-f96a-4b62-a656-c8faa0a3056f",
   "metadata": {},
   "source": [
    "## Section 2: Use LangChain\n",
    "\n",
    "We will follow this pattern for the rest of the section\n",
    "\n",
    "<li>Exploring vector databases\n",
    "<li>Basics of QA exploring simple chains\n",
    "<li>Basics of chatbot\n",
    "<li>Going to prompt templates,\n",
    "<li>Exploring Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8badc924-0982-41b0-9dde-c0523c65a9ae",
   "metadata": {},
   "source": [
    "### Exploring Vector DataBases and Create the Embeddings. \n",
    "\n",
    "Leverage SageMaker GPT-J model or the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f80f58f-da65-4f55-b1d0-ceea12a0be09",
   "metadata": {},
   "source": [
    "#### Use the file based document to retrieve based on embeddings\n",
    "\n",
    "Run the below to visualize the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8616cd-a44a-43d1-9105-cb77e0f2783a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "all_files = glob.glob(os.path.join(\"rag_data/\", \"*.csv\"))\n",
    "\n",
    "df_knowledge = pd.concat(\n",
    "    (pd.read_csv(f, header=None, names=[\"Question\", \"Answer\"]) for f in all_files),\n",
    "    axis=0,\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "#- drop \n",
    "df_answer = df_knowledge.drop([\"Question\"], axis=1)\n",
    "\n",
    "print(df_knowledge.shape)\n",
    "df_knowledge.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332a8014-e948-41cb-bce8-723b32f843fe",
   "metadata": {},
   "source": [
    "#### Convert csv to pdf\n",
    "temp.html 로컬 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5214a17a-f76c-46a4-b6e1-6db59ab03fc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install weasyprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6662c12-41ba-4f1d-97bb-471a55fa10e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# 한글 FAQ 문서 URL\n",
    "url = 'https://aws.amazon.com/ko/sagemaker/faqs'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Add a style tag with desired font\n",
    "font_tag = soup.new_tag('style')\n",
    "font_tag.string = \"@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR&display=swap'); body { font-family: 'Noto Sans KR', sans-serif; }\"\n",
    "soup.head.append(font_tag)\n",
    "\n",
    "# Save the modified HTML to a temporary file.\n",
    "with open('rag_data/temp.html', 'w') as f:\n",
    "    f.write(str(soup))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdb19a7-a1de-407c-95ab-37b7fed278f2",
   "metadata": {},
   "source": [
    "temp.html 파일을 Amazon_SageMaker_FAQs.pdf로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e75730f-bd85-457b-8223-cf2dc1be8749",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate the PDF from the modified HTML.\n",
    "\n",
    "from weasyprint import HTML\n",
    "\n",
    "HTML('rag_data/temp.html').write_pdf('rag_data/Amazon_SageMaker_FAQs.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dd8d0e-d7fe-4a10-9eb7-752cf814a9c3",
   "metadata": {},
   "source": [
    "\n",
    "## <i> 한글 PDF 파일 만드는 로직은 조금 더 고민.. 일단은 SageMaker FAQ (한글) PDF 파일은 수동으로 생성하여 rag_data에 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e149169-d6d6-4a4c-9a1f-731190df4e31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores import Chroma, AtlasDB, FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.document_loaders.csv_loader import CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c1e726-0da4-45d0-a931-b84c41513144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sagemaker, boto3, json\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.model import Model\n",
    "from sagemaker import image_uris, model_uris, script_uris, hyperparameters\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.utils import name_from_base\n",
    "from typing import Any, Dict, List, Optional\n",
    "from langchain.embeddings import SagemakerEndpointEmbeddings\n",
    "from langchain.llms.sagemaker_endpoint import ContentHandlerBase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b15420a-f564-4e68-80d0-5477640e474b",
   "metadata": {},
   "source": [
    "#### Create the embeddings for document search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6fc373-dc74-4158-955b-248347a23a61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17a0745-c55f-44ac-9949-fad03531e0d9",
   "metadata": {},
   "source": [
    "#### Vector store indexer. \n",
    "\n",
    "This is what stores and matches the embeddings.This notebook showcases Chroma and FAISS and will be transient and in memory. The VectorStore Api's are available [here](https://python.langchain.com/en/harrison-docs-refactor-3-24/reference/modules/vectorstore.html)\n",
    "\n",
    "We will use our own Custom implementation of SageMaker Embeddings which needs a reference to the SageMaker endpoint to call the model which will return the embeddings. This will be used by the FAISS or Chroma to store in memory and be used when ever the User runs a query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a09670-f92e-4d6c-8d45-e71582f81801",
   "metadata": {},
   "source": [
    "#### Use LangChain to leverage a SageMaker LLM \n",
    "\n",
    "Let's break down the above VectorstoreIndexCreator and see what's happening under the hood. Furthermore, we will see how to incorporate a customize prompt rather than using a default prompt with VectorstoreIndexCreator.\n",
    "\n",
    "Firstly, we generate embedings for each of document in the knowledge library with SageMaker  embedding model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51a86fc-835a-467f-938d-ef28ffe65e9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms.sagemaker_endpoint import SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "import ast\n",
    "\n",
    "\"\"\"\n",
    "parameters = {\n",
    "    \"max_length\": 200,\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 0.95,\n",
    "    \"do_sample\": False,\n",
    "    \"temperature\": 1,\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "parameters = {\n",
    "    \"request_output_len\": 256,\n",
    "    \"repetition_penalty\": 1.15,\n",
    "    \"temperature\": 0.1,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 1.0\n",
    "}\n",
    "\n",
    "\n",
    "MAX_CHARACTER_TRUNCATION=10000 # at 20k it produced garbage results\n",
    "\n",
    "class ContentHandlerSMLMI(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs={}) -> bytes:\n",
    "        #input_str = json.dumps({\"text_inputs\": prompt, **model_kwargs})\n",
    "        print(f\"ContentHandlerSMLMI::LangChain:::LEN:input_str={len(prompt)}:: will truncate if > {MAX_CHARACTER_TRUNCATION}::\")\n",
    "        if len(prompt) > MAX_CHARACTER_TRUNCATION:\n",
    "            prompt=prompt[:MAX_CHARACTER_TRUNCATION]\n",
    "        input_str = json.dumps({\"text_inputs\": prompt, **model_kwargs})\n",
    "        #print(f\"ContentHandlerSMLMI::LangChain:::LEN:input_str={len(input_str)}::\")\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json_dict = json.loads(output.read().decode(\"utf-8\"))\n",
    "        print(f\"ContentHandlerSMLMI::LangChain::output={response_json_dict}:\")\n",
    "        return response_json_dict[list(response_json_dict.keys())[0]] [0]\n",
    "\n",
    "\n",
    "content_handler_sm_llm = ContentHandlerSMLMI()\n",
    "session = boto3.Session()\n",
    "boto3_sm_client = boto3.client(\n",
    "    \"sagemaker-runtime\"\n",
    "    # **boto3_kwargs\n",
    ")\n",
    "print(boto3_sm_client)\n",
    "\n",
    "\n",
    "sm_llm = SagemakerEndpoint(\n",
    "    client = boto3_sm_client,\n",
    "    endpoint_name=os.environ[\"VARCO_ENDPOINT\"],\n",
    "    region_name='us-west-2',\n",
    "    model_kwargs=parameters,\n",
    "    content_handler=content_handler_sm_llm,\n",
    ")\n",
    "\n",
    "print(f\"SageMaker LLM created at {sm_llm}::\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddd8db3-d869-487c-8e20-5f8d6ab20f71",
   "metadata": {},
   "source": [
    "#### Load the Data from our Documents Source. \n",
    "\n",
    "Then we will feed this into the VectorStore to create the embeddings using the loaders like [here](https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/directory_loader.html). First we will try with the SageMaker FAQ PDF document and also the IRS PDF files\n",
    "\n",
    "we will create 3 Loaders and 3 documents after doing a split on them. 1st loader for amazon faq, 2nd for some of the IRS PDF's, 3rd just for  some ramdom example. For text it will be just a separate loader, text loader vs pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2908a10e-0e59-42f7-a8f9-9321caddb233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"rag_data/Amazon_SageMaker_FAQs.pdf\")\n",
    "documents_aws = loader.load() # -- gives 2 docs\n",
    "documents_split = loader.load_and_split() # - gives 22 docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef619e83-4246-4db2-b82d-a8ee509c3fee",
   "metadata": {},
   "source": [
    "vectorstore_faiss_aws = FAISS.from_documents(\n",
    "    CharacterTextSplitter(chunk_size=300, chunk_overlap=0).split_documents(documents_aws), \n",
    "    hf_embeddings, \n",
    "    #k=1\n",
    "    #**k_args\n",
    ")#### VectorStore as FAISS \n",
    "\n",
    "You can read up about [FAISS](https://arxiv.org/pdf/1702.08734.pdf) in memory vector store here. However for our example it will be the same \n",
    "\n",
    "Chroma\n",
    "\n",
    "[Chroma](https://www.trychroma.com/) is a super simple vector search database. The core-API consists of just four functions, allowing users to build an in-memory document-vector store. By default Chroma uses the Hugging Face transformers library to vectorize documents.\n",
    "\n",
    "Weaviate\n",
    "\n",
    "[Weaviate](https://github.com/weaviate/weaviate) is a very posh looking tool - not only does Weaviate offer a GraphQL API with support for vector search. It also allows users to vectorize their content using Weaviate's inbuilt modules or custom modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920e3778-41b9-498c-a934-8442a2716813",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import Chroma, AtlasDB, FAISS\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "\n",
    "k_args = {\"k\": 1}\n",
    "# - sub_docs = self.text_splitter.split_documents(docs)\n",
    "# - create Vectorstore\n",
    "vectorstore_faiss_aws = FAISS.from_documents(\n",
    "    CharacterTextSplitter(chunk_size=300, chunk_overlap=0).split_documents(documents_aws), \n",
    "    hf_embeddings, \n",
    "    #k=1\n",
    "    #**k_args\n",
    ")\n",
    "\n",
    "wrapper_store_faiss = VectorStoreIndexWrapper(vectorstore=vectorstore_faiss_aws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4266ed6a-0db4-4ec9-a8fe-ce0bd7f60d13",
   "metadata": {},
   "source": [
    "#### First way of running the Query. High Level abstraction\n",
    "\n",
    "Leverage VectorStoreIndexCreator which wraps around the RetrievalQA and provides a high level API abstraction to generate the response. This is a wrapper around the underlying API's which we will explore below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9470b496-acec-478d-ba96-07524af3457b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#query=\"Simplified method for business use of home deduction\"\n",
    "query=\"Amazon SageMaker 란 무엇인가\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6175596-7cb5-4f40-92eb-7cef3a50710c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wrapper_store_faiss.query(question=\"Amazon SageMaker\",llm=sm_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165e76a6-b6a5-4cc5-9e29-d0a00a3b3b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 2.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
